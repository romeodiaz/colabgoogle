{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/romeodiaz/colabgoogle/blob/main/%5BMAKE_A_COPY%5D_CVIP_%5BGE_AIVE%5D_ADK_Deploy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ADK Agent Deployment Notebook\n",
        "\n",
        "This notebook deploys agents to Vertex AI Agent Engine, mirroring the functionality of `deploy_agents.sh`.\n",
        "\n",
        "**Deployment Order:**\n",
        "1. `sales_plays_agent` (sub-agent)\n",
        "2. `company_research_agent` (sub-agent)\n",
        "3. `partnership_strategy_agent` (orchestrator)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 1. Authenticate GCP\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 2. Configuration { display-mode: \"form\" }\n",
        "\n",
        "# @markdown ### GCP Project Settings\n",
        "PROJECT_ID = \"cvip-16562\"  # @param {type:\"string\"}\n",
        "DEPLOY_REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "MODEL_REGION = \"global\"  # @param {type:\"string\"}\n",
        "STAGING_BUCKET = \"gs://partnership_strategy_agent\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### GitHub Repository (for private repos, add a Personal Access Token)\n",
        "GITHUB_REPO = \"https://github.com/NextPhase-ai/AIVE-ADK\"  # @param {type:\"string\"}\n",
        "REPO_FOLDER = \"AIVE-ADK\"  # @param {type:\"string\"}\n",
        "BRANCH_NAME = \"main\"  # @param {type:\"string\"}\n",
        "GITHUB_TOKEN = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown ### Agent Deployment Settings\n",
        "AGENTS_DIR = \"agents\"  # @param {type:\"string\"}\n",
        "AGENT_DESCRIPTION = \"ADK Agent deployed via Colab\"  # @param {type:\"string\"}\n",
        "\n",
        "# ---\n",
        "# Non-form configuration (edit in code view)\n",
        "AGENTS_TO_DEPLOY = [\"sales_plays_agent\", \"company_research_agent\", \"partnership_strategy_agent\"]\n",
        "BASE_REQUIREMENTS = [\"google-cloud-aiplatform[adk,agent_engines]\"]\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Project: {PROJECT_ID}\")\n",
        "print(f\"  Deploy Region: {DEPLOY_REGION}\")\n",
        "print(f\"  Model Region: {MODEL_REGION}\")\n",
        "print(f\"  Staging Bucket: {STAGING_BUCKET}\")\n",
        "print(f\"  GitHub Token: {'***' if GITHUB_TOKEN else '(not set)'}\")\n",
        "print(f\"  Agents to Deploy: {AGENTS_TO_DEPLOY}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 3. Clone GitHub Repo\n",
        "import os\n",
        "\n",
        "# Ensure we are in /content to avoid stale CWD issues\n",
        "CONTENT_DIR = \"/content\"\n",
        "os.makedirs(CONTENT_DIR, exist_ok=True)\n",
        "os.chdir(CONTENT_DIR)\n",
        "\n",
        "repo_path = os.path.join(CONTENT_DIR, REPO_FOLDER)\n",
        "\n",
        "# Clean up if repo already exists\n",
        "if os.path.exists(repo_path):\n",
        "    !rm -rf {repo_path}\n",
        "\n",
        "if GITHUB_TOKEN:\n",
        "    print(\"Using authenticated clone (token provided)\")\n",
        "    # Configure git to use the token\n",
        "    !git config --global credential.helper store\n",
        "    \n",
        "    # Write credentials to git credential store\n",
        "    with open(os.path.expanduser('~/.git-credentials'), 'w') as f:\n",
        "        f.write(f'https://x-access-token:{GITHUB_TOKEN}@github.com\\n')\n",
        "    \n",
        "    !git clone {GITHUB_REPO} {repo_path}\n",
        "    \n",
        "    # Clean up credentials file after clone\n",
        "    os.remove(os.path.expanduser('~/.git-credentials'))\n",
        "else:\n",
        "    print(\"Using public clone (no token)\")\n",
        "    !git clone {GITHUB_REPO} {repo_path}\n",
        "\n",
        "%cd {repo_path}\n",
        "!git checkout {BRANCH_NAME}\n",
        "\n",
        "# Verify agents directory exists\n",
        "if os.path.exists(AGENTS_DIR):\n",
        "    print(f\"\\n✓ Found agents directory: {AGENTS_DIR}\")\n",
        "    !ls -la {AGENTS_DIR}/\n",
        "else:\n",
        "    print(f\"\\n✗ Agents directory not found: {AGENTS_DIR}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 4. Install Dependencies\n",
        "!pip install -q google-cloud-aiplatform[adk,agent_engines] google-adk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 5. Initialize Vertex AI\n",
        "import vertexai\n",
        "from vertexai import agent_engines\n",
        "\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=DEPLOY_REGION,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")\n",
        "\n",
        "print(f\"✓ Vertex AI initialized\")\n",
        "print(f\"  Project: {PROJECT_ID}\")\n",
        "print(f\"  Location: {DEPLOY_REGION}\")\n",
        "print(f\"  Staging Bucket: {STAGING_BUCKET}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 6. Define Deployment Helper Functions\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import tempfile\n",
        "import importlib\n",
        "import subprocess\n",
        "import re\n",
        "import requests\n",
        "from typing import Optional, List, Dict, Any\n",
        "from datetime import datetime\n",
        "from google.api_core.exceptions import PermissionDenied\n",
        "\n",
        "\n",
        "def get_access_token() -> str:\n",
        "    \"\"\"Get GCP access token.\"\"\"\n",
        "    token = !gcloud auth print-access-token\n",
        "    return token[0].strip()\n",
        "\n",
        "\n",
        "def get_active_gcloud_account() -> Optional[str]:\n",
        "    \"\"\"Return active gcloud account if available.\"\"\"\n",
        "    try:\n",
        "        account = subprocess.check_output(\n",
        "            [\"gcloud\", \"config\", \"get-value\", \"account\"], text=True\n",
        "        ).strip()\n",
        "        return account if account and account != \"(unset)\" else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_existing_agent_engine_id(display_name: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Find existing agent engine by display name.\n",
        "    Returns the most recent engine ID if found, None otherwise.\n",
        "    \"\"\"\n",
        "    token = get_access_token()\n",
        "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "    \n",
        "    url = f\"https://{DEPLOY_REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{DEPLOY_REGION}/reasoningEngines\"\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        \n",
        "        engines = data.get('reasoningEngines', [])\n",
        "        matching = [e for e in engines if e.get('displayName') == display_name]\n",
        "        \n",
        "        if matching:\n",
        "            # Sort by createTime descending to get the most recent\n",
        "            matching.sort(key=lambda x: x.get('createTime', ''), reverse=True)\n",
        "            engine_id = matching[0]['name'].split('/')[-1]\n",
        "            return engine_id\n",
        "    except Exception as e:\n",
        "        print(f\"  Warning: Could not query existing engines: {e}\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_engine_resource(error_text: str) -> Optional[str]:\n",
        "    \"\"\"Extract reasoning engine resource path from an error string.\"\"\"\n",
        "    match = re.search(\n",
        "        r\"projects/\\d+/locations/[a-z0-9-]+/reasoningEngines/\\d+\",\n",
        "        error_text,\n",
        "    )\n",
        "    return match.group(0) if match else None\n",
        "\n",
        "\n",
        "def print_engine_log_help(resource_name: str):\n",
        "    \"\"\"Print helpful log commands for a failed reasoning engine.\"\"\"\n",
        "    print(\"  Logs: open Cloud Logging and filter by this resource name:\")\n",
        "    print(f\"    {resource_name}\")\n",
        "    print(\"  Or run in a Colab cell:\")\n",
        "    engine_id = resource_name.split(\"/\")[-1]\n",
        "    cmd = (\n",
        "        \"!gcloud logging read \"\n",
        "        \"'resource.type=\\\"aiplatform.googleapis.com/ReasoningEngine\\\" \"\n",
        "        f\"AND resource.labels.reasoning_engine_id=\\\"{engine_id}\\\"' \"\n",
        "        \"--limit=50 --freshness=2h\"\n",
        "    )\n",
        "    print(f\"    {cmd}\")\n",
        "\n",
        "\n",
        "def list_agent_files(agent_dir: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    List all Python files and data files in an agent directory.\n",
        "    Returns paths relative to the agent directory.\n",
        "    \"\"\"\n",
        "    extra_packages = []\n",
        "    \n",
        "    for root, dirs, files in os.walk(agent_dir):\n",
        "        # Skip __pycache__ and hidden directories\n",
        "        dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']\n",
        "        \n",
        "        for file in files:\n",
        "            # Skip hidden files and cache files\n",
        "            if file.startswith('.') or file.endswith('.pyc'):\n",
        "                continue\n",
        "            \n",
        "            # Include Python files, JSON files, JSONL files, and other data files\n",
        "            if file.endswith(('.py', '.json', '.jsonl', '.txt', '.yaml', '.yml')):\n",
        "                rel_path = os.path.relpath(os.path.join(root, file), agent_dir)\n",
        "                extra_packages.append(rel_path)\n",
        "    \n",
        "    return extra_packages\n",
        "\n",
        "\n",
        "def prepare_agent_staging(agent_name: str, agents_dir: str) -> str:\n",
        "    \"\"\"\n",
        "    Prepare staging directory with agent and common/ folder.\n",
        "    Returns path to the staging directory.\n",
        "    \"\"\"\n",
        "    agent_dir = os.path.join(agents_dir, agent_name)\n",
        "    common_dir = os.path.join(agents_dir, 'common')\n",
        "    \n",
        "    if not os.path.exists(agent_dir):\n",
        "        raise FileNotFoundError(f\"Agent directory not found: {agent_dir}\")\n",
        "    \n",
        "    # Create temp staging directory\n",
        "    staging_dir = tempfile.mkdtemp(prefix=f\"adk_build_{agent_name}_\")\n",
        "    staged_agent_dir = os.path.join(staging_dir, agent_name)\n",
        "    \n",
        "    # Copy agent directory\n",
        "    shutil.copytree(agent_dir, staged_agent_dir)\n",
        "    \n",
        "    # Copy common/ inside the agent folder (if exists)\n",
        "    if os.path.exists(common_dir):\n",
        "        shutil.copytree(common_dir, os.path.join(staged_agent_dir, 'common'))\n",
        "        print(f\"  ✓ Copied common/ directory into agent package\")\n",
        "    else:\n",
        "        print(f\"  ! No common/ directory found at {common_dir}\")\n",
        "\n",
        "    # Ensure packages so relative imports work\n",
        "    init_path = os.path.join(staged_agent_dir, \"__init__.py\")\n",
        "    if not os.path.exists(init_path):\n",
        "        open(init_path, \"a\").close()\n",
        "\n",
        "    common_init = os.path.join(staged_agent_dir, \"common\", \"__init__.py\")\n",
        "    if os.path.exists(os.path.dirname(common_init)) and not os.path.exists(common_init):\n",
        "        open(common_init, \"a\").close()\n",
        "    \n",
        "    return staged_agent_dir\n",
        "\n",
        "\n",
        "def load_agent_module(agent_dir: str, agent_name: str):\n",
        "    \"\"\"\n",
        "    Dynamically load the agent module from directory.\n",
        "    Returns the root_agent object.\n",
        "    \"\"\"\n",
        "    parent_dir = os.path.dirname(agent_dir)\n",
        "    for path in [parent_dir, agent_dir]:\n",
        "        if path not in sys.path:\n",
        "            sys.path.insert(0, path)\n",
        "    \n",
        "    # Clear any cached imports\n",
        "    modules_to_remove = [\n",
        "        m for m in sys.modules\n",
        "        if m == agent_name\n",
        "        or m.startswith(f\"{agent_name}.\")\n",
        "        or m.startswith('common')\n",
        "    ]\n",
        "    for m in modules_to_remove:\n",
        "        del sys.modules[m]\n",
        "    \n",
        "    # Import as a package so relative imports resolve\n",
        "    module = importlib.import_module(f\"{agent_name}.agent\")\n",
        "    importlib.reload(module)\n",
        "    \n",
        "    return module.root_agent\n",
        "\n",
        "\n",
        "def show_package_sizes(agents_dir: str, agents: List[str]):\n",
        "    \"\"\"Show package sizes for agents (helps identify bloat).\"\"\"\n",
        "    print(\"\\nAgent package sizes (smaller = faster deploy):\")\n",
        "    for agent_name in agents:\n",
        "        agent_dir = os.path.join(agents_dir, agent_name)\n",
        "        if os.path.exists(agent_dir):\n",
        "            # Calculate size\n",
        "            total_size = 0\n",
        "            for dirpath, dirnames, filenames in os.walk(agent_dir):\n",
        "                for f in filenames:\n",
        "                    fp = os.path.join(dirpath, f)\n",
        "                    total_size += os.path.getsize(fp)\n",
        "            \n",
        "            # Format size\n",
        "            if total_size > 1024 * 1024:\n",
        "                size_str = f\"{total_size / (1024*1024):.1f}M\"\n",
        "            elif total_size > 1024:\n",
        "                size_str = f\"{total_size / 1024:.1f}K\"\n",
        "            else:\n",
        "                size_str = f\"{total_size}B\"\n",
        "            \n",
        "            print(f\"  {agent_name}: {size_str}\")\n",
        "        else:\n",
        "            print(f\"  {agent_name}: NOT FOUND\")\n",
        "    print()\n",
        "\n",
        "\n",
        "print(\"✓ Helper functions defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 7. Define Main Deployment Function\n",
        "import time\n",
        "from vertexai import agent_engines\n",
        "\n",
        "\n",
        "def deploy_agent(\n",
        "    agent_name: str,\n",
        "    agents_dir: str,\n",
        "    requirements: List[str],\n",
        "    description: str = \"ADK Agent\"\n",
        ") -> Optional[Any]:\n",
        "    \"\"\"\n",
        "    Deploy a single agent to Vertex AI Agent Engine.\n",
        "    Updates existing agent if found, creates new otherwise.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    original_dir = os.getcwd()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"DEPLOYING: {agent_name}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        # Step 1: Check for existing agent\n",
        "        print(f\"\\n  Step 1/4: Checking for existing agent...\")\n",
        "        existing_id = get_existing_agent_engine_id(agent_name)\n",
        "        \n",
        "        if existing_id:\n",
        "            print(f\"  ✓ Found existing agent: {existing_id}\")\n",
        "            resource_name = f\"projects/{PROJECT_ID}/locations/{DEPLOY_REGION}/reasoningEngines/{existing_id}\"\n",
        "        else:\n",
        "            print(f\"  ! No existing agent found, will create new\")\n",
        "            resource_name = None\n",
        "        \n",
        "        # Step 2: Prepare staging directory with common/\n",
        "        print(f\"\\n  Step 2/4: Preparing staging directory...\")\n",
        "        staged_agent_dir = prepare_agent_staging(agent_name, agents_dir)\n",
        "        print(f\"  ✓ Staging directory: {staged_agent_dir}\")\n",
        "        \n",
        "        # Step 3: Load agent module (need to be in the directory)\n",
        "        print(f\"\\n  Step 3/4: Loading agent module...\")\n",
        "        os.chdir(staged_agent_dir)\n",
        "        root_agent = load_agent_module(staged_agent_dir, agent_name)\n",
        "        print(f\"  ✓ Loaded agent: {root_agent}\")\n",
        "        \n",
        "        # Get extra packages from staged directory (now relative paths work)\n",
        "        extra_packages = list_agent_files(staged_agent_dir)\n",
        "        print(f\"  ✓ Found {len(extra_packages)} files to package\")\n",
        "        \n",
        "        # Step 4: Deploy (from the agent directory so relative paths work)\n",
        "        print(f\"\\n  Step 4/4: Deploying to Agent Engine...\")\n",
        "        \n",
        "        if resource_name:\n",
        "            # Update existing\n",
        "            print(f\"  Updating existing agent...\")\n",
        "            remote_app = agent_engines.update(\n",
        "                resource_name=resource_name,\n",
        "                agent_engine=root_agent,\n",
        "                description=description,\n",
        "                requirements=requirements,\n",
        "                extra_packages=extra_packages,\n",
        "            )\n",
        "        else:\n",
        "            # Create new\n",
        "            print(f\"  Creating new agent...\")\n",
        "            remote_app = agent_engines.create(\n",
        "                agent_engine=root_agent,\n",
        "                display_name=agent_name,\n",
        "                description=description,\n",
        "                requirements=requirements,\n",
        "                extra_packages=extra_packages,\n",
        "            )\n",
        "        \n",
        "        # Return to original directory\n",
        "        os.chdir(original_dir)\n",
        "        \n",
        "        # Cleanup staging directory\n",
        "        shutil.rmtree(os.path.dirname(staged_agent_dir), ignore_errors=True)\n",
        "        \n",
        "        duration = time.time() - start_time\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(f\"✓ {agent_name} deployed successfully ({duration:.1f}s)\")\n",
        "        print(f\"  Resource: {remote_app.resource_name}\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        return remote_app\n",
        "        \n",
        "    except Exception as e:\n",
        "        # Make sure we return to original directory on error\n",
        "        os.chdir(original_dir)\n",
        "        duration = time.time() - start_time\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(f\"✗ {agent_name} deployment FAILED ({duration:.1f}s)\")\n",
        "        print(f\"  Error: {e}\")\n",
        "        if isinstance(e, PermissionDenied):\n",
        "            account = get_active_gcloud_account()\n",
        "            if account:\n",
        "                print(f\"  Active gcloud account: {account}\")\n",
        "            print(\"  Fix: grant IAM permission 'aiplatform.reasoningEngines.create'\")\n",
        "            print(\"  Suggested roles: roles/aiplatform.user or roles/aiplatform.admin\")\n",
        "            print(\"  Also ensure bucket permissions: roles/storage.objectAdmin or roles/storage.admin\")\n",
        "        else:\n",
        "            resource_name = extract_engine_resource(str(e))\n",
        "            if resource_name:\n",
        "                print_engine_log_help(resource_name)\n",
        "        print(\"=\" * 60)\n",
        "        raise\n",
        "\n",
        "\n",
        "def deploy_all_agents(\n",
        "    agents: List[str],\n",
        "    agents_dir: str,\n",
        "    requirements: List[str],\n",
        "    description: str = \"ADK Agent\"\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Deploy all agents sequentially.\n",
        "    Returns dict of agent_name -> deployed app.\n",
        "    \"\"\"\n",
        "    total_start = time.time()\n",
        "    \n",
        "    print(\"\\n\" + \"#\" * 60)\n",
        "    print(\"#          ADK AGENT DEPLOYMENT TO VERTEX AI               #\")\n",
        "    print(\"#\" * 60)\n",
        "    \n",
        "    # Show package sizes\n",
        "    show_package_sizes(agents_dir, agents)\n",
        "    \n",
        "    print(\"Deployment Plan:\")\n",
        "    for i, agent in enumerate(agents, 1):\n",
        "        agent_type = \"orchestrator\" if i == len(agents) else \"sub-agent\"\n",
        "        print(f\"  {i}. {agent} ({agent_type})\")\n",
        "    print()\n",
        "    \n",
        "    deployed_apps = {}\n",
        "    \n",
        "    for agent_name in agents:\n",
        "        try:\n",
        "            app = deploy_agent(\n",
        "                agent_name=agent_name,\n",
        "                agents_dir=agents_dir,\n",
        "                requirements=requirements,\n",
        "                description=description,\n",
        "            )\n",
        "            deployed_apps[agent_name] = app\n",
        "        except Exception as e:\n",
        "            print(f\"\\n! Stopping deployment due to error in {agent_name}\")\n",
        "            break\n",
        "    \n",
        "    total_duration = time.time() - total_start\n",
        "    \n",
        "    print(\"\\n\" + \"#\" * 60)\n",
        "    print(\"#          DEPLOYMENT COMPLETE                             #\")\n",
        "    print(\"#\" * 60)\n",
        "    print(f\"\\n  Total time: {total_duration:.1f}s\")\n",
        "    print(f\"  Agents deployed: {len(deployed_apps)}/{len(agents)}\")\n",
        "    \n",
        "    print(\"\\nDeployed Resources:\")\n",
        "    for name, app in deployed_apps.items():\n",
        "        print(f\"  {name}: {app.resource_name}\")\n",
        "    \n",
        "    print(f\"\\nView agents in Cloud Console:\")\n",
        "    print(f\"  https://console.cloud.google.com/vertex-ai/agents?project={PROJECT_ID}\")\n",
        "    \n",
        "    return deployed_apps\n",
        "\n",
        "\n",
        "print(\"✓ Deployment functions defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 8. Deploy All Agents (Run This Cell)\n",
        "# This deploys all agents in order: sub-agents first, then orchestrator\n",
        "\n",
        "deployed_apps = deploy_all_agents(\n",
        "    agents=AGENTS_TO_DEPLOY,\n",
        "    agents_dir=AGENTS_DIR,\n",
        "    requirements=BASE_REQUIREMENTS,\n",
        "    description=AGENT_DESCRIPTION,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Alternative: Deploy Single Agent\n",
        "\n",
        "Use the cells below to deploy a single agent or test locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 9. Deploy Single Agent (Optional) { display-mode: \"form\" }\n",
        "# @markdown Select which agent to deploy individually\n",
        "\n",
        "SINGLE_AGENT = \"partnership_strategy_agent\"  # @param [\"sales_plays_agent\", \"company_research_agent\", \"partnership_strategy_agent\"]\n",
        "\n",
        "single_app = deploy_agent(\n",
        "    agent_name=SINGLE_AGENT,\n",
        "    agents_dir=AGENTS_DIR,\n",
        "    requirements=BASE_REQUIREMENTS,\n",
        "    description=AGENT_DESCRIPTION,\n",
        ")\n",
        "\n",
        "print(f\"\\nDeployed: {single_app.resource_name}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Testing Deployed Agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 10. Test Agent: Create Session\n",
        "# @markdown Test a deployed agent by creating a session\n",
        "\n",
        "TEST_AGENT = \"partnership_strategy_agent\"  # @param {type:\"string\"}\n",
        "TEST_USER_ID = \"test_user_123\"  # @param {type:\"string\"}\n",
        "\n",
        "# Get the deployed app (either from deploy_all or deploy_single)\n",
        "if TEST_AGENT in deployed_apps:\n",
        "    test_app = deployed_apps[TEST_AGENT]\n",
        "elif 'single_app' in dir() and single_app:\n",
        "    test_app = single_app\n",
        "else:\n",
        "    # Fetch existing agent\n",
        "    existing_id = get_existing_agent_engine_id(TEST_AGENT)\n",
        "    if existing_id:\n",
        "        resource_name = f\"projects/{PROJECT_ID}/locations/{DEPLOY_REGION}/reasoningEngines/{existing_id}\"\n",
        "        test_app = agent_engines.get(resource_name)\n",
        "    else:\n",
        "        raise ValueError(f\"Agent {TEST_AGENT} not found\")\n",
        "\n",
        "print(f\"Testing agent: {test_app.resource_name}\")\n",
        "\n",
        "# Create session via API\n",
        "token = get_access_token()\n",
        "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "data = {'class_method': 'async_create_session', 'input': {'user_id': TEST_USER_ID}}\n",
        "endpoint = f'https://{DEPLOY_REGION}-aiplatform.googleapis.com/v1/{test_app.resource_name}:query'\n",
        "\n",
        "res = requests.post(endpoint, headers=headers, json=data)\n",
        "print(f\"\\nResponse ({res.status_code}):\")\n",
        "print(res.json())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 11. Test Agent: Send Query\n",
        "# @markdown Send a test message to the agent\n",
        "\n",
        "TEST_MESSAGE = \"hello\"  # @param {type:\"string\"}\n",
        "\n",
        "data = {\n",
        "    'class_method': 'async_stream_query',\n",
        "    'input': {\n",
        "        'user_id': TEST_USER_ID,\n",
        "        'message': TEST_MESSAGE\n",
        "    }\n",
        "}\n",
        "endpoint = f'https://{DEPLOY_REGION}-aiplatform.googleapis.com/v1/{test_app.resource_name}:streamQuery?alt=sse'\n",
        "\n",
        "res = requests.post(endpoint, headers=headers, json=data)\n",
        "print(f\"Response ({res.status_code}):\")\n",
        "print(res.text[:2000] if len(res.text) > 2000 else res.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Local Testing with ADK CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 12. Test Agent Locally (ADK CLI)\n",
        "# @markdown Run an agent locally using `adk run`\n",
        "\n",
        "LOCAL_TEST_AGENT = \"sales_plays_agent\"  # @param [\"sales_plays_agent\", \"company_research_agent\", \"partnership_strategy_agent\"]\n",
        "\n",
        "agent_path = os.path.join(AGENTS_DIR, LOCAL_TEST_AGENT)\n",
        "print(f\"Running: adk run {agent_path}\")\n",
        "print(\"Press Ctrl+C to stop\\n\")\n",
        "\n",
        "!cd {agent_path} && adk run ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Utility: List All Deployed Agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 13. List All Agent Engines in Project\n",
        "\n",
        "token = get_access_token()\n",
        "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
        "url = f\"https://{DEPLOY_REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{DEPLOY_REGION}/reasoningEngines\"\n",
        "\n",
        "res = requests.get(url, headers=headers)\n",
        "data = res.json()\n",
        "\n",
        "engines = data.get('reasoningEngines', [])\n",
        "print(f\"Found {len(engines)} Agent Engine(s):\\n\")\n",
        "\n",
        "for engine in engines:\n",
        "    name = engine.get('displayName', 'N/A')\n",
        "    engine_id = engine['name'].split('/')[-1]\n",
        "    created = engine.get('createTime', 'N/A')[:19]\n",
        "    print(f\"  {name}\")\n",
        "    print(f\"    ID: {engine_id}\")\n",
        "    print(f\"    Created: {created}\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}